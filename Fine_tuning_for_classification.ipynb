{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "86dNEafRq3EO"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S20Tyo6csj7",
        "outputId": "0483b90f-6e46-445f-f737-28acd549d6be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Define file paths\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
        "    \"\"\"\n",
        "    Downloads and extracts the SMS Spam Collection dataset if not already present.\n",
        "    \"\"\"\n",
        "    # Check if the dataset already exists\n",
        "    if data_file_path.exists():\n",
        "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
        "        return\n",
        "\n",
        "    # Download the zip file\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        with open(zip_path, \"wb\") as out_file:\n",
        "            out_file.write(response.read())\n",
        "\n",
        "    # Extract the zip file\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extracted_path)\n",
        "\n",
        "    # Rename the extracted file to include the .tsv extension\n",
        "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "    os.rename(original_file_path, data_file_path)\n",
        "\n",
        "    print(f\"File downloaded and saved as {data_file_path}\")\n",
        "\n",
        "# Execute the function\n",
        "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\n",
        " data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"]\n",
        ")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "mzudaiSbc_Lh",
        "outputId": "37566766-a372-43f5-f483-38445e0d5ef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Label                                               Text\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham               Will ü b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c57c3a68-99cc-4e47-ab1a-62959180ffc9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c57c3a68-99cc-4e47-ab1a-62959180ffc9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c57c3a68-99cc-4e47-ab1a-62959180ffc9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c57c3a68-99cc-4e47-ab1a-62959180ffc9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8cac143a-15fd-4972-b10a-e294c05f5a72\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8cac143a-15fd-4972-b10a-e294c05f5a72')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8cac143a-15fd-4972-b10a-e294c05f5a72 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7d443ab0-1c75-4178-8528-f07c867f2603\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7d443ab0-1c75-4178-8528-f07c867f2603 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset preparation"
      ],
      "metadata": {
        "id": "86dNEafRq3EO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"Label\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45FaEOVqdkF0",
        "outputId": "65d77c58-8843-49fd-e6d1-9b3b119be6df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def create_balanced_dataset(df):\n",
        "    \"\"\"\n",
        "    Creates a balanced dataset by undersampling the 'ham' messages to match the number of 'spam' messages.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): The input DataFrame containing a \"Label\" column with 'spam' and 'ham' values.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A balanced DataFrame with an equal number of 'spam' and 'ham' messages.\n",
        "    \"\"\"\n",
        "    # Count the number of spam messages\n",
        "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
        "\n",
        "    # Randomly sample the same number of ham messages\n",
        "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
        "\n",
        "    # Combine the sampled ham messages with all spam messages\n",
        "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
        "\n",
        "    return balanced_df\n",
        "\n",
        "# Create the balanced dataset\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "\n",
        "# Display the counts of each label\n",
        "print(balanced_df[\"Label\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEWyQds1dpdD",
        "outputId": "c120290b-348d-45ed-b20c-1367ca39da1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     747\n",
            "spam    747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(balanced_df[\"Label\"].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbvfA9WtepwS",
        "outputId": "551ca40f-5159-4e2c-b95a-1c1e1709c065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ham' 'spam']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
        "print(balanced_df[\"Label\"].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "er36PouVeDIt",
        "outputId": "30bf4170-b8e9-4ef8-f350-aaea4463c300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def random_split(df, train_frac, validation_frac):\n",
        "    \"\"\"\n",
        "    Splits a DataFrame into training, validation, and test sets.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): The input DataFrame to be split.\n",
        "        train_frac (float): The fraction of data to be used for training.\n",
        "        validation_frac (float): The fraction of data to be used for validation.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Three DataFrames - (train_df, validation_df, test_df)\n",
        "    \"\"\"\n",
        "    # Shuffle the dataset randomly\n",
        "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "\n",
        "    # Compute split indices\n",
        "    train_end = int(len(df) * train_frac)\n",
        "    validation_end = train_end + int(len(df) * validation_frac)\n",
        "\n",
        "    # Split the dataset\n",
        "    train_df = df[:train_end]\n",
        "    validation_df = df[train_end:validation_end]\n",
        "    test_df = df[validation_end:]\n",
        "\n",
        "    return train_df, validation_df, test_df\n",
        "\n",
        "# Perform the split on the balanced dataset\n",
        "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
        "\n",
        "# Print dataset sizes\n",
        "print(f\"Training set size: {len(train_df)}\")\n",
        "print(f\"Validation set size: {len(validation_df)}\")\n",
        "print(f\"Test set size: {len(test_df)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-asVZRRYeK0c",
        "outputId": "47c522c5-e7b2-4f0b-e03d-9d73b4437a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 1045\n",
            "Validation set size: 149\n",
            "Test set size: 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)\n"
      ],
      "metadata": {
        "id": "tA1IvBZ-etE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJCD2pCJhI-M",
        "outputId": "16433ca8-a372-418e-da06-e157a2c33ffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-M0clt5fOpH",
        "outputId": "ebf2b2c2-de09-4d4e-904b-e9df01002dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SpamDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom PyTorch Dataset for SMS Spam Classification.\n",
        "\n",
        "    Parameters:\n",
        "        csv_file (str): Path to the CSV file containing text and labels.\n",
        "        tokenizer: Tokenizer used to encode the text.\n",
        "        max_length (int, optional): Maximum length of encoded sequences. If None, uses the longest sequence in the dataset.\n",
        "        pad_token_id (int): Token ID used for padding.\n",
        "\n",
        "    Returns:\n",
        "        torch.utils.data.Dataset: A PyTorch dataset with tokenized and padded text inputs.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "\n",
        "        # Tokenize all text samples\n",
        "        self.encoded_texts = [tokenizer.encode(text) for text in self.data[\"Text\"]]\n",
        "\n",
        "        # Determine max sequence length\n",
        "        if max_length is None:\n",
        "            self.max_length = self._longest_encoded_length()\n",
        "        else:\n",
        "            self.max_length = max_length\n",
        "\n",
        "        # Truncate longer sequences\n",
        "        self.encoded_texts = [\n",
        "            encoded_text[:self.max_length] for encoded_text in self.encoded_texts\n",
        "        ]\n",
        "\n",
        "        # Pad shorter sequences\n",
        "        self.encoded_texts = [\n",
        "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
        "            for encoded_text in self.encoded_texts\n",
        "        ]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Returns a single data sample (tokenized text and label).\n",
        "        \"\"\"\n",
        "        encoded = self.encoded_texts[index]\n",
        "        label = self.data.iloc[index][\"Label\"]\n",
        "        return (\n",
        "            torch.tensor(encoded, dtype=torch.long),\n",
        "            torch.tensor(label, dtype=torch.long),\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the total number of samples in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def _longest_encoded_length(self):\n",
        "        \"\"\"\n",
        "        Finds the longest encoded sequence length in the dataset.\n",
        "        \"\"\"\n",
        "        return max(len(encoded_text) for encoded_text in self.encoded_texts)\n"
      ],
      "metadata": {
        "id": "V8AQtF6ohGG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SpamDataset(\n",
        " csv_file=\"train.csv\",\n",
        " max_length=None,\n",
        " tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "l3iN9Zf3lhvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the number of tokens in the longest sequence\n",
        "print(train_dataset.max_length)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLAgOhFrlxve",
        "outputId": "c90d9c6e-1eca-4d3a-f025-2e95a030286d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pad the validation and test sets to match the length of the longest training sequence\n",
        "val_dataset = SpamDataset(\n",
        " csv_file=\"validation.csv\",\n",
        " max_length=train_dataset.max_length,\n",
        " tokenizer=tokenizer\n",
        ")\n",
        "test_dataset = SpamDataset(\n",
        " csv_file=\"test.csv\",\n",
        " max_length=train_dataset.max_length,\n",
        " tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "VLQcmkALmLd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# Define DataLoader parameters\n",
        "num_workers = 0  # Number of subprocesses for data loading\n",
        "batch_size = 8    # Number of samples per batch\n",
        "\n",
        "# Create DataLoaders for training, validation, and test sets\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,      # Shuffle training data\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True     # Drop last incomplete batch (if any)\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,     # No need to shuffle validation data\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False    # Keep all batches\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,     # No need to shuffle test data\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False    # Keep all batches\n",
        ")\n"
      ],
      "metadata": {
        "id": "Z0IfTEj8mvbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_batch, target_batch in train_loader:\n",
        " pass\n",
        "print(\"Input batch dimensions:\", input_batch.shape)\n",
        "print(\"Label batch dimensions\", target_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2NATxIToB5m",
        "outputId": "238507ea-6b3f-4b5d-d49e-6310d313bf32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch dimensions: torch.Size([8, 120])\n",
            "Label batch dimensions torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBwv_IMZqDBQ",
        "outputId": "8d1295c3-1c55-4785-936f-182dcd58f977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 training batches\n",
            "19 validation batches\n",
            "38 test batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model setup"
      ],
      "metadata": {
        "id": "pVqqc25kqv3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "INPUT_PROMPT = \"Every effort moves\""
      ],
      "metadata": {
        "id": "KrinprXWqUsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_CONFIG = {\n",
        " \"vocab_size\": 50257,\n",
        " \"context_length\": 1024,\n",
        " \"drop_rate\": 0.0,\n",
        " \"qkv_bias\": True\n",
        "}\n",
        "model_configs = {\n",
        " \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        " \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        " \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        " \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n"
      ],
      "metadata": {
        "id": "KedHEhFXrAvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "url = (\n",
        " \"https://raw.githubusercontent.com/rasbt/\"\n",
        " \"LLMs-from-scratch/main/ch05/\"\n",
        " \"01_main-chapter-code/gpt_download.py\"\n",
        ")\n",
        "filename = url.split('/')[-1]\n",
        "urllib.request.urlretrieve(url, filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTvEM-D5r92s",
        "outputId": "35697fe2-9db2-472c-8d62-8a0cb685d2bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('gpt_download.py', <http.client.HTTPMessage at 0x7d660a295ad0>)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def assign(left, right):\n",
        "    \"\"\"\n",
        "    Assigns values from `right` to `left`, ensuring shape compatibility.\n",
        "\n",
        "    Parameters:\n",
        "        left (torch.Tensor): Target tensor.\n",
        "        right (numpy.ndarray or torch.Tensor): Source tensor.\n",
        "\n",
        "    Returns:\n",
        "        torch.nn.Parameter: The assigned tensor wrapped as a trainable parameter.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the shapes of `left` and `right` do not match.\n",
        "    \"\"\"\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "\n",
        "    return torch.nn.Parameter(torch.tensor(right))\n"
      ],
      "metadata": {
        "id": "_uNi06ex1ELn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#loads the weights from the params dictionary into a GPTModel instance gpt.\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    \"\"\"\n",
        "    Loads pre-trained weights into a GPT model.\n",
        "\n",
        "    Parameters:\n",
        "        gpt (GPTModel): The GPT model instance.\n",
        "        params (dict): Dictionary containing pre-trained weights.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    # Assign token and position embeddings\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "    # Load transformer block weights\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        block_params = params[\"blocks\"][b][\"attn\"][\"c_attn\"]\n",
        "\n",
        "        # Split Q, K, V weight matrices\n",
        "        q_w, k_w, v_w = np.split(block_params[\"w\"], 3, axis=-1)\n",
        "\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        # Split Q, K, V bias vectors\n",
        "        q_b, k_b, v_b = np.split(block_params[\"b\"], 3, axis=-1)\n",
        "\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        # Load output projection weights\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T\n",
        "        )\n"
      ],
      "metadata": {
        "id": "2ei3KZxIyXOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements Multi-Head Self-Attention mechanism.\n",
        "\n",
        "    Parameters:\n",
        "        d_in (int): Input dimension.\n",
        "        d_out (int): Output dimension (must be divisible by num_heads).\n",
        "        context_length (int): Maximum sequence length for attention masking.\n",
        "        dropout (float): Dropout rate for attention weights.\n",
        "        num_heads (int): Number of attention heads.\n",
        "        qkv_bias (bool, optional): Whether to include bias in query, key, value projections.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "\n",
        "        # Ensure output dimension is divisible by number of heads\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads  # Dimension per head\n",
        "\n",
        "        # Linear projections for query, key, and value\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "        # Output projection\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Attention mask (upper triangular matrix to prevent attending to future tokens)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of multi-head attention.\n",
        "\n",
        "        Parameters:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, seq_length, d_in).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor of shape (batch_size, seq_length, d_out).\n",
        "        \"\"\"\n",
        "        batch_size, num_tokens, d_in = x.shape\n",
        "\n",
        "        # Compute queries, keys, and values\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # Reshape to (batch_size, seq_length, num_heads, head_dim)\n",
        "        keys = keys.view(batch_size, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(batch_size, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(batch_size, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose for attention computation: (batch_size, num_heads, seq_length, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute attention scores: (batch_size, num_heads, seq_length, seq_length)\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "\n",
        "        # Apply mask to prevent attending to future tokens\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        # Compute attention weights using softmax\n",
        "        attn_weights = torch.softmax(attn_scores / (keys.shape[-1] ** 0.5), dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Compute weighted sum of values\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Reshape back to (batch_size, seq_length, d_out)\n",
        "        context_vec = context_vec.contiguous().view(batch_size, num_tokens, self.d_out)\n",
        "\n",
        "        # Apply final projection\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "\n",
        "        return context_vec\n"
      ],
      "metadata": {
        "id": "FbAimU9m2GxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements the Gaussian Error Linear Unit (GELU) activation function.\n",
        "\n",
        "    GELU is commonly used in Transformer-based models as an alternative to ReLU.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the GELU activation function.\n",
        "\n",
        "        Parameters:\n",
        "            x (torch.Tensor): Input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor after applying GELU activation.\n",
        "        \"\"\"\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n"
      ],
      "metadata": {
        "id": "pyxldqnO3hYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements a feedforward neural network used in Transformer models.\n",
        "\n",
        "    Parameters:\n",
        "        cfg (dict): Configuration dictionary containing model hyperparameters.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "\n",
        "        # Define the feedforward network\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),  # Expand embedding dimension\n",
        "            GELU(),  # Non-linearity\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"])  # Project back to original dimension\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the feedforward network.\n",
        "\n",
        "        Parameters:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, seq_length, emb_dim).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor of the same shape as input.\n",
        "        \"\"\"\n",
        "        return self.layers(x)\n"
      ],
      "metadata": {
        "id": "cJHT-UEC2Wg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements Layer Normalization, which normalizes inputs across the last dimension.\n",
        "\n",
        "    Parameters:\n",
        "        emb_dim (int): Dimension of the input embeddings.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5  # Small constant to prevent division by zero\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))  # Learnable scaling factor\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))  # Learnable shifting factor\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of Layer Normalization.\n",
        "\n",
        "        Parameters:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, seq_length, emb_dim).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Normalized tensor with the same shape as input.\n",
        "        \"\"\"\n",
        "        mean = x.mean(dim=-1, keepdim=True)  # Compute mean along last dimension\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)  # Compute variance\n",
        "\n",
        "        # Normalize the input\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "\n",
        "        # Scale and shift\n",
        "        return self.scale * norm_x + self.shift\n"
      ],
      "metadata": {
        "id": "bzS2Hf9l3tsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A single transformer block consisting of multi-head attention and\n",
        "    a feedforward network with residual connections.\n",
        "\n",
        "    Parameters:\n",
        "        cfg (dict): Configuration dictionary containing model hyperparameters.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "\n",
        "        # Multi-head attention layer\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"]\n",
        "        )\n",
        "\n",
        "        # Feedforward layer\n",
        "        self.ff = FeedForward(cfg)\n",
        "\n",
        "        # Layer normalization\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "\n",
        "        # Dropout for residual connections\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the transformer block.\n",
        "\n",
        "        Parameters:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, seq_length, emb_dim).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor of the same shape as input.\n",
        "        \"\"\"\n",
        "        # First residual connection with multi-head attention\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Residual connection\n",
        "\n",
        "        # Second residual connection with feedforward network\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Residual connection\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "BEfB9h0-1h5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple implementation of a GPT model using PyTorch.\n",
        "\n",
        "    Parameters:\n",
        "        cfg (dict): Configuration dictionary containing model hyperparameters.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "\n",
        "        # Token and position embeddings\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        # Transformer blocks\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
        "        )\n",
        "\n",
        "        # Final normalization and output head\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        \"\"\"\n",
        "        Forward pass of the GPT model.\n",
        "\n",
        "        Parameters:\n",
        "            in_idx (torch.Tensor): Input tensor of shape (batch_size, seq_len).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Logits for each token in the sequence.\n",
        "        \"\"\"\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "\n",
        "        # Compute token and position embeddings\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "\n",
        "        # Add embeddings and pass through transformer blocks\n",
        "        x = self.drop_emb(tok_embeds + pos_embeds)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "\n",
        "        return logits  # Fixed typo (was 'logit')\n"
      ],
      "metadata": {
        "id": "BRp-9x1j0To5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(\n",
        " model_size=model_size, models_dir=\"gpt2\"\n",
        ")\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adbVWYM3rLe6",
        "outputId": "9caeba88-7325-4c2a-a2e7-110fc00e4ce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 121kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 2.10MiB/s]\n",
            "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 126kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:47<00:00, 10.4MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 6.81MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 1.56MiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.43MiB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Settings:\", settings)\n",
        "print(\"Parameter dictionary keys:\", params.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mje4MIgNohQE",
        "outputId": "f468b8c2-9dce-41d3-da52-efdaa30a3808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
            "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(params[\"wte\"])\n",
        "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2OwrfJSomhG",
        "outputId": "c6a9effe-5340-432c-bde9-0e4b215bea69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
            "   0.04531523]\n",
            " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
            "   0.04318958]\n",
            " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
            "  -0.08785918]\n",
            " ...\n",
            " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
            "  -0.06952604]\n",
            " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
            "  -0.02245961]\n",
            " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
            "   0.12067825]]\n",
            "Token embedding weight tensor dimensions: (50257, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    \"\"\"\n",
        "    Generates text using an autoregressive model.\n",
        "\n",
        "    Parameters:\n",
        "        model (torch.nn.Module): The trained language model.\n",
        "        idx (torch.Tensor): Initial input tensor (batch_size, sequence_length).\n",
        "        max_new_tokens (int): Number of tokens to generate.\n",
        "        context_size (int): Number of tokens used as context for generation.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Generated token sequence.\n",
        "    \"\"\"\n",
        "    for _ in range(max_new_tokens):\n",
        "        # Extract the most recent `context_size` tokens\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)  # Get model predictions\n",
        "            logits = logits[:, -1, :]  # Take logits of the last generated token\n",
        "\n",
        "            # Compute probability distribution using softmax\n",
        "            probas = torch.softmax(logits, dim=-1)\n",
        "\n",
        "            # Select the most probable token\n",
        "            idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "\n",
        "            # Append new token to the sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "    return idx\n"
      ],
      "metadata": {
        "id": "yYjhg13Pr0_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_token_ids(text, tokenizer):\n",
        "    \"\"\"\n",
        "    Converts a given text string into token IDs using a tokenizer.\n",
        "\n",
        "    Parameters:\n",
        "        text (str): The input text to tokenize.\n",
        "        tokenizer: The tokenizer to use for encoding.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Tensor containing tokenized text.\n",
        "    \"\"\"\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # Add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    \"\"\"\n",
        "    Converts token IDs back to a text string using a tokenizer.\n",
        "\n",
        "    Parameters:\n",
        "        token_ids (torch.Tensor): Tensor containing tokenized text.\n",
        "        tokenizer: The tokenizer to use for decoding.\n",
        "\n",
        "    Returns:\n",
        "        str: Decoded text from token IDs.\n",
        "    \"\"\"\n",
        "    flat = token_ids.squeeze(0)  # Remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())\n"
      ],
      "metadata": {
        "id": "LV_DHMhT5N6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input text\n",
        "text_1 = \"Hello\"\n",
        "\n",
        "# Generate tokenized text using the model\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_1, tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "# Convert generated tokens back to text and print the output\n",
        "print(token_ids_to_text(token_ids, tokenizer))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCIxcsYi5Wv7",
        "outputId": "f7a949c6-3134-42fb-cd6c-e21c644eb656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Gideon roaming cancersprop Mannypropproppropproppropproppropproppropprop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input text\n",
        "text_2 = (\n",
        "    \"Is the following text 'spam'? Answer with 'yes' or 'no': \"\n",
        "    \"'You are a winner! You have been specially \"\n",
        "    \"selected to receive $1000 cash or a $2000 award.'\"\n",
        ")\n",
        "\n",
        "# Generate tokenized text using the model\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_2, tokenizer),\n",
        "    max_new_tokens=23,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "# Convert generated tokens back to text and print the output\n",
        "print(token_ids_to_text(token_ids, tokenizer))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A2plLLf5rkY",
        "outputId": "26279c2f-ee62-4ea1-c808-3f836fca5a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner! You have been specially selected to receive $1000 cash or a $2000 award.' Eck Moines ceremony equality Moines Moines Moines Moines Moinesprop Ottawa Moineslist ceremony ceremony Layoutlist Moines Moinesorearequires Moinesorea\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding a classification head"
      ],
      "metadata": {
        "id": "LRC-iEdipXZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "E-uLiIbk6OHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcfc39de-1878-469a-e22b-20e68af276ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        " param.requires_grad = False"
      ],
      "metadata": {
        "id": "V-tq14g-pTyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "num_classes = 2\n",
        "model.out_head = torch.nn.Linear(\n",
        " in_features=BASE_CONFIG[\"emb_dim\"],\n",
        " out_features=num_classes\n",
        ")"
      ],
      "metadata": {
        "id": "Qvpw4sBuqIza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.trf_blocks[-1].parameters():\n",
        " param.requires_grad = True\n",
        "for param in model.final_norm.parameters():\n",
        " param.requires_grad = True"
      ],
      "metadata": {
        "id": "3DnO3kavqT1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer.encode(\"Do you have time\")\n",
        "inputs = torch.tensor(inputs).unsqueeze(0)\n",
        "print(\"Inputs:\", inputs)\n",
        "print(\"Inputs dimensions:\", inputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJO8k1jlqvhX",
        "outputId": "a0ca1c3a-f6d5-4bc9-ced0-202f83668b17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs: tensor([[5211,  345,  423,  640]])\n",
            "Inputs dimensions: torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        " outputs = model(inputs)\n",
        "print(\"Outputs:\\n\", outputs)\n",
        "print(\"Outputs dimensions:\", outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC6GkjzFq9V9",
        "outputId": "373b06fb-aac4-4f29-f929-ea1d6d3f4ab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs:\n",
            " tensor([[[0.9587, 1.1429],\n",
            "         [1.1648, 0.1673],\n",
            "         [1.0093, 0.1638],\n",
            "         [0.9381, 0.1998]]])\n",
            "Outputs dimensions: torch.Size([1, 4, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Last output token:\", outputs[:, -1, :])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLIHcpuJrIlF",
        "outputId": "8aa1f0d0-0807-451d-ce40-fdebee31d7cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last output token: tensor([[0.9381, 0.1998]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
        "label = torch.argmax(probas)\n",
        "print(\"Class label:\", label.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn0HFpj1swRt",
        "outputId": "12736b31-62f2-476c-cfe2-d87000752f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = outputs[:, -1, :]\n",
        "label = torch.argmax(logits)\n",
        "print(\"Class label:\", label.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVismhC6wDsJ",
        "outputId": "92006616-8a3c-4f12-f2e7-14372923099f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "    model.eval()\n",
        "    correct_predictions, num_examples = 0, 0\n",
        "\n",
        "    if num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            input_batch = input_batch.to(device)\n",
        "            target_batch = target_batch.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                logits = model(input_batch)[:, -1, :]\n",
        "                predicted_labels = torch.argmax(logits, dim=-1)\n",
        "                num_examples += predicted_labels.shape[0]\n",
        "                correct_predictions += (predicted_labels == target_batch).sum().item()\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return correct_predictions / num_examples\n"
      ],
      "metadata": {
        "id": "Xqqr0CnrxQpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "torch.manual_seed(123)\n",
        "train_accuracy = calc_accuracy_loader(\n",
        " train_loader, model, device, num_batches=10\n",
        ")\n",
        "val_accuracy = calc_accuracy_loader(\n",
        " val_loader, model, device, num_batches=10\n",
        ")\n",
        "test_accuracy = calc_accuracy_loader(\n",
        " test_loader, model, device, num_batches=10\n",
        ")\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOARbihGwV4d",
        "outputId": "573072c3-5853-4c3d-8f35-f9b259094537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 55.00%\n",
            "Validation accuracy: 55.00%\n",
            "Test accuracy: 52.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch = input_batch.to(device)\n",
        "    target_batch = target_batch.to(device)\n",
        "\n",
        "    logits = model(input_batch)[:, -1, :]\n",
        "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
        "\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "2ju557lAxOrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.0\n",
        "\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return total_loss / num_batches\n"
      ],
      "metadata": {
        "id": "xPT1nuj2yUsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
        "\n",
        "print(f\"Training loss: {train_loss:.3f}\")\n",
        "print(f\"Validation loss: {val_loss:.3f}\")\n",
        "print(f\"Test loss: {test_loss:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQjW33D-yhDQ",
        "outputId": "e51379ca-d21a-47f4-c8eb-e1e8ead47d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.817\n",
            "Validation loss: 0.801\n",
            "Test loss: 0.882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning the model on supervised data"
      ],
      "metadata": {
        "id": "KxxDpOAsy7y8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def train_classifier_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs, eval_freq, eval_iter\n",
        "):\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    examples_seen, global_step = 0, -1\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            examples_seen += input_batch.shape[0]\n",
        "            global_step += 1\n",
        "\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter\n",
        "                )\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, \"\n",
        "                      f\"Val loss {val_loss:.3f}\")\n",
        "\n",
        "                train_accuracy = calc_accuracy_loader(\n",
        "                    train_loader, model, device, num_batches=eval_iter\n",
        "                )\n",
        "                val_accuracy = calc_accuracy_loader(\n",
        "                    val_loader, model, device, num_batches=eval_iter\n",
        "                )\n",
        "\n",
        "                print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "                print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "\n",
        "                train_accs.append(train_accuracy)\n",
        "                val_accs.append(val_accuracy)\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n"
      ],
      "metadata": {
        "id": "AnG8TQ06yjOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n"
      ],
      "metadata": {
        "id": "wK2F3C-HzlKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "\n",
        "# Set number of epochs\n",
        "num_epochs = 5\n",
        "\n",
        "# Train the model\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=50, eval_iter=5\n",
        ")\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "\n",
        "# Print execution time\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4redjIYLz1UE",
        "outputId": "7a5e3fee-89e7-49f6-a35a-22f3cfbf8740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 0.853, Val loss 0.794\n",
            "Training accuracy: 50.00% | Validation accuracy: 50.00%\n",
            "Ep 1 (Step 000050): Train loss 0.592, Val loss 0.637\n",
            "Training accuracy: 80.00% | Validation accuracy: 70.00%\n",
            "Ep 1 (Step 000100): Train loss 0.597, Val loss 0.575\n",
            "Training accuracy: 80.00% | Validation accuracy: 77.50%\n",
            "Ep 2 (Step 000150): Train loss 0.450, Val loss 0.532\n",
            "Training accuracy: 80.00% | Validation accuracy: 82.50%\n",
            "Ep 2 (Step 000200): Train loss 0.442, Val loss 0.619\n",
            "Training accuracy: 90.00% | Validation accuracy: 77.50%\n",
            "Ep 2 (Step 000250): Train loss 0.510, Val loss 0.493\n",
            "Training accuracy: 82.50% | Validation accuracy: 77.50%\n",
            "Ep 3 (Step 000300): Train loss 0.389, Val loss 0.475\n",
            "Training accuracy: 87.50% | Validation accuracy: 80.00%\n",
            "Ep 3 (Step 000350): Train loss 0.283, Val loss 0.525\n",
            "Training accuracy: 85.00% | Validation accuracy: 85.00%\n",
            "Ep 4 (Step 000400): Train loss 0.282, Val loss 0.458\n",
            "Training accuracy: 85.00% | Validation accuracy: 80.00%\n",
            "Ep 4 (Step 000450): Train loss 0.261, Val loss 0.467\n",
            "Training accuracy: 90.00% | Validation accuracy: 85.00%\n",
            "Ep 4 (Step 000500): Train loss 0.187, Val loss 0.406\n",
            "Training accuracy: 97.50% | Validation accuracy: 80.00%\n",
            "Ep 5 (Step 000550): Train loss 0.218, Val loss 0.445\n",
            "Training accuracy: 85.00% | Validation accuracy: 87.50%\n",
            "Ep 5 (Step 000600): Train loss 0.114, Val loss 0.419\n",
            "Training accuracy: 87.50% | Validation accuracy: 85.00%\n",
            "Training completed in 1.15 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Plotting the classification**"
      ],
      "metadata": {
        "id": "u8W3KrIo0eEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation values\n",
        "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
        "\n",
        "    # Labels and legend\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        "\n",
        "    # Second x-axis for examples seen\n",
        "    ax2 = ax1.twiny()\n",
        "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot to set scale\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "\n",
        "    # Adjust layout and save the plot\n",
        "    fig.tight_layout()\n",
        "    plt.savefig(f\"{label}-plot.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "# Generate epoch and examples_seen tensors for plotting\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "\n",
        "# Plot the training and validation loss\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "GMsbJmaZz5Lz",
        "outputId": "7077300f-e7f0-41bf-e047-c2fcf898312e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
        "plot_values(\n",
        " epochs_tensor, examples_seen_tensor, train_accs, val_accs,\n",
        " label=\"accuracy\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "W4EEbPo71j6J",
        "outputId": "0f70092e-687c-4346-9c70-fa94a467256d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWaofceM1k5I",
        "outputId": "bd59db8f-719a-4c7f-c0d0-49cc606da370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 93.17%\n",
            "Validation accuracy: 85.91%\n",
            "Test accuracy: 84.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the model to classify new texts"
      ],
      "metadata": {
        "id": "vvboQJVv1-dT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def classify_review(\n",
        "    text, model, tokenizer, device, max_length=None, pad_token_id=50256\n",
        "):\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize input text\n",
        "    input_ids = tokenizer.encode(text)\n",
        "\n",
        "    # Get supported context length\n",
        "    supported_context_length = model.pos_emb.weight.shape[1]\n",
        "\n",
        "    # Trim or pad input to match max_length\n",
        "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
        "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
        "\n",
        "    # Convert to tensor and add batch dimension\n",
        "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_tensor)[:, -1, :]\n",
        "        predicted_label = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    return \"spam\" if predicted_label == 1 else \"not spam\"\n"
      ],
      "metadata": {
        "id": "NzUUPcvn1rKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = (\n",
        " \"You are a winner you have been specially\"\n",
        " \" selected to receive $1000 cash or a $2000 award.\"\n",
        ")\n",
        "print(classify_review(\n",
        " text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtXnfrxq2B0d",
        "outputId": "66e54d2b-b5f5-4329-ae14-3b1309593f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = (\n",
        " \"Hey, just wanted to check if we're still on\"\n",
        " \" for dinner tonight? Let me know!\"\n",
        ")\n",
        "print(classify_review(\n",
        " text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU_oLAz32E-U",
        "outputId": "8b999bef-041d-4b49-f409-440a304ef17a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = (\n",
        "    \"Congratulations! You have won a free vacation to the Bahamas! \"\n",
        "    \"Click the link to claim your prize now!\"\n",
        ")\n",
        "print(classify_review(text_2, model, tokenizer, device, max_length=train_dataset.max_length))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Anr1lZvC2oiQ",
        "outputId": "73ecb0c3-fedf-4ab1-df26-3dd2286ecd99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_3 = (\n",
        "    \"Hey, are we still meeting for coffee tomorrow morning? Let me know what time works for you.\"\n",
        ")\n",
        "print(classify_review(text_3, model, tokenizer, device, max_length=train_dataset.max_length))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo3fIBGe2rcP",
        "outputId": "5d0d5e55-a2dd-4010-af17-bb5710b2d24a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_4 = (\n",
        "    \"Important notice: Your bank account has been compromised. \"\n",
        "    \"Please verify your identity immediately by logging into your account.\"\n",
        ")\n",
        "print(classify_review(text_4, model, tokenizer, device, max_length=train_dataset.max_length))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzLXSNf32vs5",
        "outputId": "6ee8463e-c596-4458-a571-b78a8526e308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"review_classifier.pth\")"
      ],
      "metadata": {
        "id": "qp1HYzqV2KuZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}